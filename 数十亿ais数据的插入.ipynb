{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 当数据很多时，内存资源显得十分宝贵，合理利用内存非常重要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import threading\n",
    "from pymongo import MongoClient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "threadNum = 128\n",
    "folderNum = 8\n",
    "osm = MongoClient('192.168.168.7', 5077)\n",
    "au = osm.admin.authenticate(\"sa\",\"6hNmEVCd\",mechanism=\"SCRAM-SHA-1\")\n",
    "db = osm.aisdata\n",
    "col = db.shipInfo\n",
    "erCol = db.shipInfoError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = \"/root/ais/data/2018/trajectory%s/\" %( folderNum )  #数据文件\n",
    "TASK = \"/root/ais/Projects/month%s/\" %( folderNum )      #工作路径"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  1.分割任务\n",
    " **将每月的数据分为foldernum份，每一份又分为threadNum份**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tasksplit = 10        #分割为10个文件夹\n",
    "createVar = locals()\n",
    "dataDir = DATA\n",
    "taskListDir = TASK\n",
    "taskdir = os.path.join(taskListDir, \"folder%02d\" % (folderNum)) \n",
    "Var = locals()\n",
    "filePath = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 扫描所有数据文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spliting files finashed.\n",
      "\n",
      "All txt: 84990\n"
     ]
    }
   ],
   "source": [
    "if os.path.exists(taskdir):\n",
    "    print(\"spliting files finashed.\\n\")\n",
    "else:\n",
    "    os.mkdir(taskdir)\n",
    "for root, dirs, files in os.walk(dataDir):      #扫描所有数据文件名\n",
    "    for file in files:  \n",
    "        if file.endswith('txt'):\n",
    "            filePath.append(os.path.join(root, file))\n",
    "print(\"All txt: %d\" % ( len(filePath) ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将所有将要插入的数据分为tasksplit个"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tasksplit):          #生成tasksplit个list \n",
    "    queue = \"%02d\" % ( i )\n",
    "    createVar[\"fileQueue\" + queue] = []    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(filePath)):      #分配task给每一个tasksplit\n",
    "    queue = \"%02d\" % (i % tasksplit)\n",
    "    createVar[\"fileQueue\" + queue].append(filePath[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8499\n",
      "8499\n",
      "8499\n",
      "8499\n",
      "8499\n",
      "8499\n",
      "8499\n",
      "8499\n",
      "8499\n",
      "8499\n"
     ]
    }
   ],
   "source": [
    "for i in range(tasksplit):          #打印出每个tasksplit长度\n",
    "    queue = \"%02d\" % ( i )\n",
    "    print(len(createVar[\"fileQueue\" + queue]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 将每个tasksplit分为threadNum份"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(tasksplit):          #生成文件夹\n",
    "    queue = \"%02d\" % ( i )\n",
    "    taskdirnum = os.path.join(taskdir,\"Task%s\"%(queue))\n",
    "    if not os.path.isdir(taskdirnum):\n",
    "        os.mkdir(taskdirnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for m in range(threadNum*tasksplit):          #256*10个Var[]\n",
    "    Vqu = \"%02d\" % ( m )\n",
    "    Var[\"fqueue\" + Vqu] = []\n",
    "for j in range(tasksplit):      #0\n",
    "    ques = \"%02d\" % ( j )         #0\n",
    "    cVarlen = len(createVar[\"fileQueue\" + ques])   #16330\n",
    "    queVar = j*threadNum   # 256*j \n",
    "    for k in range(cVarlen):      #16330\n",
    "        Vqu = k % threadNum\n",
    "        Varque = \"%02d\" % (Vqu+queVar)    #64\n",
    "        Var[\"fqueue\" + Varque].append(createVar[\"fileQueue\" + ques][k])    #64*256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'fqueue2559'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-271127d6d2f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"fqueue2559\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'fqueue2559'"
     ]
    }
   ],
   "source": [
    "len(Var[\"fqueue25\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分配所有任务到每一个文件夹里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task00 folder task00.txt has 66 pieces task.\n",
      "Task00 folder task01.txt has 66 pieces task.\n",
      "Task00 folder task02.txt has 66 pieces task.\n",
      "Task00 folder task03.txt has 66 pieces task.\n",
      "Task00 folder task04.txt has 66 pieces task.\n",
      "Task00 folder task05.txt has 66 pieces task.\n",
      "Task00 folder task06.txt has 66 pieces task.\n",
      "...",
      "trajectory8 thread 71 assigned 66 pieces of data.\n",
      "trajectory8 thread 71 assigned 3 pieces of data.\n",
      "trajectory8 thread 71 assigned 110808 pieces of data.\n",
      "trajectory8 thread 121 assigned 3 pieces of data.\n",
      "trajectory8 thread 121 assigned 2 pieces of data.\n",
      "trajectory8 thread 121 assigned 2 pieces of data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectory8 thread 59 assigned 10128 pieces of data.\n",
      "trajectory8 thread 4 assigned 2 pieces of data.\n",
      "trajectory8 thread 4 assigned 1608 pieces of data.\n",
      "trajectory8 thread 4 assigned 18 pieces of data.\n",
      "trajectory8 thread 4 assigned 2 pieces of data.\n",
      "trajectory8 thread 117 assigned 3 pieces of data.\n",
      "trajectory8 thread 117 assigned 3 pieces of data.\n",
      "trajectory8 thread 117 assigned 125 pieces of data.\n",
      "trajectory8 thread 117 assigned 3 pieces of data.\n",
      "trajectory8 thread 98 assigned 3 pieces of data.\n",
      "trajectory8 thread 98 assigned 2 pieces of data.\n",
      "trajectory8 thread 98 assigned 3 pieces of data.\n",
      "trajectory8 thread 127 assigned 296 pieces of data.\n",
      "trajectory8 thread 127 assigned 2 pieces of data.\n",
      "trajectory8 thread 123 assigned 2 pieces of data.\n",
      "trajectory8 thread 123 assigned 2 pieces of data.\n",
      "trajectory8 thread 123 assigned 2 pieces of data.\n",
      "trajectory8 thread 123 assigned 2 pieces of data.\n",
      "trajectory8 thread 52 assigned 2 pieces of data.\n",
      "trajectory8 thread 120 assigned 2 pieces of data.\n",
      "trajectory8 thread 120 assigned 2 pieces of data.\n",
      "trajectory8 thread 120 assigned 1539 pieces of data.\n",
      "trajectory8 thread 0 assigned 734 pieces of data.\n",
      "trajectory8 thread 0 assigned 7 pieces of data.\n",
      "trajectory8 thread 0 assigned 2 pieces of data.\n",
      "None\n",
      "all data have inserted\n",
      "end\n",
      "All threads finished, used 152 seconds.\n",
      "0 pieces of data (389915941) has been inserted, 4865237 errors happened.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:17: DeprecationWarning: count is deprecated. Use Collection.count_documents instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trajectory8 thread 71 assigned 2 pieces of data.\n",
      "trajectory8 thread 3 assigned 2 pieces of data.\n",
      "trajectory8 thread 11 assigned 39372 pieces of data.\n",
      "trajectory8 thread 11 assigned 2 pieces of data.\n",
      "trajectory8 thread 11 assigned 2 pieces of data.\n",
      "trajectory8 thread 11 assigned 3 pieces of data.\n"
     ]
    }
   ],
   "source": [
    "# MAIN\n",
    "START = datetime.datetime.now()\n",
    "strSTART = START.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open (os.path.join(TASK, \"%02d_time.log\" % ( folderNum )), \"a\") as l:\n",
    "    l.write(strSTART + \"\\n\")\n",
    "#######################################################################\n",
    "TOTAL = 0\n",
    "for i in yield_insert(1):\n",
    "    print(i)\n",
    "######################################################################    \n",
    "END = datetime.datetime.now()\n",
    "strEND = END.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open (os.path.join(TASK, \"%02d_time.log\" % ( folderNum )), \"a\") as lg:\n",
    "    lg.write(strEND)\n",
    "DELTA = (END - START).seconds\n",
    "print(\"All threads finished, used %s seconds.\" % (DELTA))\n",
    "print(\"%d pieces of data (%d) has been inserted, %d errors happened.\" %( TOTAL, col.find().count(), erCol.find().count() ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for在数据非常多时很占内存，然后用yeild生成器执行十次main， 不报错，但是发现服务器一条数据也没插入，莫名其妙"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_insert(n):\n",
    "    for i in range(n):\n",
    "        yield main(i)\n",
    "    print(\"all data have inserted\") \n",
    "    print(\"end\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 下面是为断点续插，插入进度可视化的探索，但是不能插入数据，弃用了"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class threadInsert(threading.Thread):\n",
    "    def __init__(self, queue, fileList, col, erCol, strtask):\n",
    "        threading.Thread.__init__(self)\n",
    "        self.queue = queue\n",
    "        self.fileList = fileList\n",
    "        self.col = col\n",
    "        self.erCol = erCol\n",
    "        self.strtask = strtask\n",
    "\n",
    "    def run(self):\n",
    "        total = 0\n",
    "        with open(self.fileList, \"r\") as taskList:\n",
    "            taskList = taskList.read().split(\"\\n\")\n",
    "            \n",
    "        for txt in taskList:\n",
    "            if txt == \"\":\n",
    "                continue\n",
    "            else:\n",
    "                with open(txt, \"r\") as data:\n",
    "                    data = data.readlines()\n",
    "                month = strtask + \" \"+ os.path.dirname(txt)[-11:]\n",
    "                print(\"%s thread %s assigned %s pieces of data.\" % (month, self.queue, len(data) ))\n",
    "                total += len(data)\n",
    "\n",
    "                col_insert = []\n",
    "                erCol_insert = []\n",
    "                for c in data:\n",
    "                    a = insertData(c, self.col, self.erCol, col_insert, erCol_insert)\n",
    "\n",
    "        self.result = total\n",
    "\n",
    "    def getResult(self):\n",
    "        try:\n",
    "            return self.result\n",
    "        except:\n",
    "            return Exception\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = datetime.datetime.now()\n",
    "strSTART = START.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "with open (os.path.join(TASK, \"%02d_time.log\" % ( folderNum )), \"a\") as tlog:\n",
    "    tlog.write(strSTART + \"\\n\")\n",
    "############################################\n",
    "\n",
    "TOTAL = 0\n",
    "#for j in range(threadNum):\n",
    "TaskFolder = os.path.join(TASK, \"folder%02d\" %(folderNum), \"Task00\")\n",
    "threads = []\n",
    "try:\n",
    "    for i in range(threadNum):\n",
    "        queue = \"%02d\" % ( i )\n",
    "        taskFile = os.path.join(TaskFolder, \"task%s.txt\" % ( queue ))\n",
    "        strtask = \"Task%02d \"%(j) + taskFile[-10:]\n",
    "        t = threadInsert(queue=i, fileList=taskFile, col=col, erCol=erCol, strtask=strtask)\n",
    "        t.start()\n",
    "        threads.append(t)\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "        result = t.getResult()\n",
    "        TOTAL += result\n",
    "        print(\"finished %d pieces of data.\" % ( result ))\n",
    "except:\n",
    "    CUR = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(os.path.join(TASK, \"error.log\"), \"a\") as erLog:\n",
    "        erLog.write(CUR + \"\\n\")\n",
    "        erLog.write(\"%02d\" % ( folderNum ) + \" - \" + str(Exception) + \"\\n\")\n",
    "#############################################  \n",
    "\n",
    "END = datetime.datetime.now()\n",
    "strEND = END.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "with open (os.path.join(TASK, \"%02d_time.log\" % ( folderNum )), \"a\") as tlog:\n",
    "    tlog.write(strEND)\n",
    "    \n",
    "DELTA = (END - START).seconds\n",
    "\n",
    "print(\"All threads finished, used %s seconds.\" % (DELTA))\n",
    "print(\"%d pieces of data (%d) has been inserted, %d errors happened.\" %( TOTAL, col.find().count(), erCol.find().count() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "START = datetime.datetime.now()\n",
    "strSTART = START.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open (os.path.join(TASK, \"%02d_time.log\" % ( folderNum )), \"w\") as tlog:\n",
    "    tlog.write(strSTART + \"\\n\")\n",
    "\n",
    "Total = 0\n",
    "try:\n",
    "    for j in range(16, threadNum):\n",
    "        threads = []\n",
    "        TOTAL = 0\n",
    "        startque = datetime.datetime.now()\n",
    "        queues = \"%02d\" % ( j )\n",
    "        taskFile = os.path.join(TASK, \"folder%02d\" %(folderNum), \"task%s.txt\" % ( queues ))\n",
    "#        if os.path.exist(taskFile):\n",
    "        strtask = taskFile[-10:]\n",
    "        for i in range(threadNum):\n",
    "            t = threadInsert(queue=i, fileList=taskFile, col=col, erCol=erCol, strtask=strtask)\n",
    "            t.start()\n",
    "            threads.append(t)\n",
    "        os.remove(taskFile)\n",
    "        costque = (datetime.datetime.now() - startque).seconds\n",
    "        for t in threads:\n",
    "            t.join()\n",
    "            result = t.getResult()\n",
    "            TOTAL += result\n",
    "        Total += TOTAL\n",
    "        rstr = strtask[:-4] + \"finished %d pieces of data.\" % ( TOTAL )\n",
    "        with open (os.path.join(TASK, \"%02d_time.log\" % ( folderNum )), \"a\") as l:\n",
    "            l.write(rstr + \"cost %s seconds \"%(costque) + \"\\n\")\n",
    "        # print(\"%d pieces of data finished, %d errors.\" % ( col.find().count(), erCol.find().count() ))\n",
    "\n",
    "except:\n",
    "    CUR = datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "    with open(os.path.join(TASK, \"error.log\"), \"a\") as erLog:\n",
    "        erLog.write(CUR + \"\\n\")\n",
    "        erLog.write(\"%02d\" % ( folderNum ) + \" - \" + str(Exception) + \"\\n\")\n",
    "\n",
    "END = datetime.datetime.now()\n",
    "strEND = END.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "with open (os.path.join(TASK, \"%02d_time.log\" % ( folderNum )), \"a\") as tlog:\n",
    "    tlog.write(strEND)\n",
    "    \n",
    "DELTA = (END - START).seconds\n",
    "print(\"All threads finished, used %s seconds.\" % (DELTA))\n",
    "print(\"%d pieces of data (%d) has been inserted, %d errors happened.\" %( Total, col.find().count(), erCol.find().count() ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initTask(dataDir, taskListDir):\n",
    "    taskdir = os.path.join(taskListDir, \"folder%02d\" % (folderNum))   #/root/ais/Projects/month%d/folder%d\n",
    "    if os.path.exists(taskdir):\n",
    "        print(\"spliting files finashed.\\n\")\n",
    "        return\n",
    "\n",
    "    filePath = []       #保存所有txt文件的绝对路径\n",
    "\n",
    "    for root, dirs, files in os.walk(dataDir):      #扫描所有数据文件名\n",
    "        for file in files:  \n",
    "            if file.endswith('txt'):\n",
    "                filePath.append(os.path.join(root, file))   \n",
    "\n",
    "    print(\"All txt: %d\" % ( len(filePath) ))\n",
    "\n",
    "    for i in range(threadNum):          #循环执行所有线程\n",
    "        queue = \"%02d\" % ( i )\n",
    "        createVar[\"fileQueue\" + queue] = []    #生成threadNum个list 保存filepath\n",
    "        \n",
    "    for i in range(len(filePath)):      #将所有txt文件分为 Threadnum 份\n",
    "        queue = \"%02d\" % (i % threadNum)\n",
    "        createVar[\"fileQueue\" + queue].append(filePath[i])\n",
    "\n",
    "    for i in range(threadNum):          #\n",
    "        queue = \"%02d\" % ( i )\n",
    "        if not os.path.isdir(taskdir):           #/root/ais/Projects/month%d/folder%d/Task%s/ 不存在则创建\n",
    "            os.mkdir(taskdir)\n",
    "        tasknum = os.path.join(taskdir,\"Task%s\"%(queue))\n",
    "        if not os.path.isdir(tasknum):\n",
    "            os.mkdir(tasknum)\n",
    "            #文件夹task00:\n",
    "            \n",
    "        for j in range(threadNum):\n",
    "            que = \"%02d\" % ( j )\n",
    "#            if not os.path.isdir(taskdir,\"Task%s\"%(queue)):     #/root/ais/Projects/month%d/folder%d/Task%s/ 不存在则创建\n",
    " #               os.mkdir(taskdir,\"Task%s\"%(queue))\n",
    "                \n",
    "            fn = os.path.join(taskdir ,\"Task%s\"%(queue),\"task%s.txt\" % (que))    #folder%d/task%s.txt\n",
    "            if os.path.isfile(fn):                              #删除目录下已存在的task%s.txt文件\n",
    "                os.remove(fn)\n",
    "                \n",
    "            for m in range(threadNum):          #\n",
    "                Queue = \"%02d\" % ( m )\n",
    "                Var[\"fileQueue\" + Queue] = []\n",
    "                #128*Var[] = createVar[]\n",
    "                \n",
    "            for k in range(len(createVar[\"fileQueue\" + queue])):      #createVar[00] \n",
    "                qu = \"%02d\" % (k % threadNum)\n",
    "                Var[\"fileQueue\" + qu].append(createVar[\"fileQueue\" + queue][k])\n",
    "                \n",
    "            with open(fn, \"a\") as task:                   #将createVar[\"fileQueue\" + queue]写入task%s.txt\n",
    "                for file in Var[\"fileQueue\" + que]:      \n",
    "                    task.write(file + \"\\n\")\n",
    "\n",
    "            print(\"Task%s task%s: %d\" % (queue, que, len(Var[\"fileQueue\" + que])))\n",
    "            Var[\"fileQueue\" + que] = []\n",
    "            fn = []\n",
    "        \n",
    "    # release memory        \n",
    "    createVar[\"fileQueue\" + queue] = []\n",
    "\n",
    "    print(\"spliting files finished.\\n\")\n",
    "\n",
    "    # release memory\n",
    "    filePath = []\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
